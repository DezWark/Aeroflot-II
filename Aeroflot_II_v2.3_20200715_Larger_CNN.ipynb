{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use bonus plates (length of 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "#import qgrid\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "#from keras.callbacks import TensorBoard\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as mpatches\n",
    "#%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "LEARNING_RATE = 0.01\n",
    "UPDATE_TARGET_NET = 1000\n",
    "\n",
    "# Definitions\n",
    "GAMES_TO_PLAY = 120001\n",
    "REPLAY_MEMORY_SIZE = 131072\n",
    "DYNAMIC_LEARNING_EPOCHS = 2\n",
    "MINIBATCH_SIZE = 64\n",
    "NUMBER_OF_MOVES_IN_GAME = 50\n",
    "GAMMA = 0.99\n",
    "\n",
    "# Variables\n",
    "MAXIMUM_SCORE = 0\n",
    "TOTAL_SCORE_100 = 0.0\n",
    "AVG_SCORE_HIST = []\n",
    "TOTAL_SUCCESSFUL_MOVES_100 = 0.0\n",
    "AVG_SUCC_MOVES_HIST = []\n",
    "CNN_MOVE_PROB = 0.1\n",
    "CNN_MOVES_COUNT = 0\n",
    "CNN_SUCCESSFUL_PREDICTION = 0\n",
    "\n",
    "# Initialize replay_memory\n",
    "replay_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Definitions\n",
    "#\n",
    "# RED = 0.2\n",
    "# GREEN = 0.4\n",
    "# BLUE = 0.6\n",
    "# PURPLE = 0.8\n",
    "#\n",
    "colors = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "moves = {1: ((0, 0), (1, 0)), 2: ((0, 1), (1, 1)), 3: ((0, 2), (1, 2)), 4: ((0, 3), (1, 3)), 5: ((0, 4), (1, 4)), \n",
    "         6: ((0, 5), (1, 5)), 7: ((1, 0), (2, 0)), 8: ((1, 0), (0, 0)), 9: ((1, 1), (2, 1)), 10: ((1, 1), (0, 1)), \n",
    "         11: ((1, 2), (2, 2)), 12: ((1, 2), (0, 2)), 13: ((1, 3), (2, 3)), 14: ((1, 3), (0, 3)), 15: ((1, 4), (2, 4)), \n",
    "         16: ((1, 4), (0, 4)), 17: ((1, 5), (2, 5)), 18: ((1, 5), (0, 5)), 19: ((2, 0), (3, 0)), 20: ((2, 0), (1, 0)), \n",
    "         21: ((2, 1), (3, 1)), 22: ((2, 1), (1, 1)), 23: ((2, 2), (3, 2)), 24: ((2, 2), (1, 2)), 25: ((2, 3), (3, 3)), \n",
    "         26: ((2, 3), (1, 3)), 27: ((2, 4), (3, 4)), 28: ((2, 4), (1, 4)), 29: ((2, 5), (3, 5)), 30: ((2, 5), (1, 5)), \n",
    "         31: ((3, 0), (4, 0)), 32: ((3, 0), (2, 0)), 33: ((3, 1), (4, 1)), 34: ((3, 1), (2, 1)), 35: ((3, 2), (4, 2)), \n",
    "         36: ((3, 2), (2, 2)), 37: ((3, 3), (4, 3)), 38: ((3, 3), (2, 3)), 39: ((3, 4), (4, 4)), 40: ((3, 4), (2, 4)), \n",
    "         41: ((3, 5), (4, 5)), 42: ((3, 5), (2, 5)), 43: ((4, 0), (5, 0)), 44: ((4, 0), (3, 0)), 45: ((4, 1), (5, 1)), \n",
    "         46: ((4, 1), (3, 1)), 47: ((4, 2), (5, 2)), 48: ((4, 2), (3, 2)), 49: ((4, 3), (5, 3)), 50: ((4, 3), (3, 3)), \n",
    "         51: ((4, 4), (5, 4)), 52: ((4, 4), (3, 4)), 53: ((4, 5), (5, 5)), 54: ((4, 5), (3, 5)), 55: ((5, 0), (6, 0)), \n",
    "         56: ((5, 0), (4, 0)), 57: ((5, 1), (6, 1)), 58: ((5, 1), (4, 1)), 59: ((5, 2), (6, 2)), 60: ((5, 2), (4, 2)), \n",
    "         61: ((5, 3), (6, 3)), 62: ((5, 3), (4, 3)), 63: ((5, 4), (6, 4)), 64: ((5, 4), (4, 4)), 65: ((5, 5), (6, 5)), \n",
    "         66: ((5, 5), (4, 5)), 67: ((6, 0), (5, 0)), 68: ((6, 1), (5, 1)), 69: ((6, 2), (5, 2)), 70: ((6, 3), (5, 3)), \n",
    "         71: ((6, 4), (5, 4)), 72: ((6, 5), (5, 5)), 73: ((0, 0), (0, 1)), 74: ((1, 0), (1, 1)), 75: ((2, 0), (2, 1)), \n",
    "         76: ((3, 0), (3, 1)), 77: ((4, 0), (4, 1)), 78: ((5, 0), (5, 1)), 79: ((6, 0), (6, 1)), 80: ((0, 1), (0, 0)), \n",
    "         81: ((0, 1), (0, 2)), 82: ((1, 1), (1, 0)), 83: ((1, 1), (1, 2)), 84: ((2, 1), (2, 0)), 85: ((2, 1), (2, 2)), \n",
    "         86: ((3, 1), (3, 0)), 87: ((3, 1), (3, 2)), 88: ((4, 1), (4, 0)), 89: ((4, 1), (4, 2)), 90: ((5, 1), (5, 0)), \n",
    "         91: ((5, 1), (5, 2)), 92: ((6, 1), (6, 0)), 93: ((6, 1), (6, 2)), 94: ((0, 2), (0, 1)), 95: ((0, 2), (0, 3)), \n",
    "         96: ((1, 2), (1, 1)), 97: ((1, 2), (1, 3)), 98: ((2, 2), (2, 1)), 99: ((2, 2), (2, 3)), 100: ((3, 2), (3, 1)), \n",
    "         101: ((3, 2), (3, 3)), 102: ((4, 2), (4, 1)), 103: ((4, 2), (4, 3)), 104: ((5, 2), (5, 1)), 105: ((5, 2), (5, 3)), \n",
    "         106: ((6, 2), (6, 1)), 107: ((6, 2), (6, 3)), 108: ((0, 3), (0, 2)), 109: ((0, 3), (0, 4)), 110: ((1, 3), (1, 2)), \n",
    "         111: ((1, 3), (1, 4)), 112: ((2, 3), (2, 2)), 113: ((2, 3), (2, 4)), 114: ((3, 3), (3, 2)), 115: ((3, 3), (3, 4)), \n",
    "         116: ((4, 3), (4, 2)), 117: ((4, 3), (4, 4)), 118: ((5, 3), (5, 2)), 119: ((5, 3), (5, 4)), 120: ((6, 3), (6, 2)), \n",
    "         121: ((6, 3), (6, 4)), 122: ((0, 4), (0, 3)), 123: ((0, 4), (0, 5)), 124: ((1, 4), (1, 3)), 125: ((1, 4), (1, 5)), \n",
    "         126: ((2, 4), (2, 3)), 127: ((2, 4), (2, 5)), 128: ((3, 4), (3, 3)), 129: ((3, 4), (3, 5)), 130: ((4, 4), (4, 3)), \n",
    "         131: ((4, 4), (4, 5)), 132: ((5, 4), (5, 3)), 133: ((5, 4), (5, 5)), 134: ((6, 4), (6, 3)), 135: ((6, 4), (6, 5)), \n",
    "         136: ((0, 5), (0, 4)), 137: ((1, 5), (1, 4)), 138: ((2, 5), (2, 4)), 139: ((3, 5), (3, 4)), 140: ((4, 5), (4, 4)), \n",
    "         141: ((5, 5), (5, 4)), 142: ((6, 5), (6, 4))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_fits(field, i, j, new_color):\n",
    "    \"\"\"\n",
    "    Checks if two items to the left or two colors to the top are NOT of the same color as the new item.\n",
    "    Input:\n",
    "    - field: battfield, numpy array\n",
    "    - i, j: position on the new item, int, within field.shape\n",
    "    - new_color: color of the new item, float\n",
    "    Output:\n",
    "    - boolean: True, if the new item is ok\n",
    "    \"\"\"\n",
    "    # Check two colors to the left\n",
    "    if (j > 1):\n",
    "        if (round(field[i, j - 2] % 1.0, 1) == new_color) and (round(field[i, j - 1] % 1.0, 1) == new_color):\n",
    "            return False\n",
    "        \n",
    "    # Check two colors to the right\n",
    "    if (j < 4):\n",
    "        if (round(field[i, j + 2] % 1.0, 1) == new_color) and (round(field[i, j + 1] % 1.0, 1) == new_color):\n",
    "            return False\n",
    "    \n",
    "    # Check two color to the top\n",
    "    if (i < 5):\n",
    "        if (round(field[i + 2, j] % 1.0, 1) == new_color) and (round(field[i + 1, j] % 1.0, 1) == new_color):\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_field(field):\n",
    "    \"\"\"\n",
    "    Initialization of the battle field.\n",
    "    Move from bottom left corner and add new elements.\n",
    "    Input: \n",
    "    - field: numpy array of zeros, 7x6\n",
    "    Output:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    \"\"\"\n",
    "    colors = [0.2, 0.4, 0.6, 0.8]\n",
    "    \n",
    "    for i in list(range(field.shape[0]))[::-1]:\n",
    "        for j in range(field.shape[1]):\n",
    "            rd.seed()\n",
    "            new_color = rd.choice(colors)\n",
    "            \n",
    "            while not color_fits(field, i, j, new_color):\n",
    "                rd.seed()\n",
    "                new_color = rd.choice(colors)\n",
    "                \n",
    "            field[i, j] = new_color\n",
    "    \n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_field(field):\n",
    "    \"\"\"\n",
    "    Visualizes the battle field in colored circles\n",
    "    Handles bonus plates\n",
    "    Input:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    Output:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 7))\n",
    "\n",
    "    ax.set_xlim((0, 10))\n",
    "    ax.set_ylim((0, 13))\n",
    "\n",
    "    circles = []\n",
    "\n",
    "    for ii in range(7):\n",
    "        for jj in range(6):\n",
    "            if (round(field[ii, jj] % 1.0, 1) == 0.2):\n",
    "                clr = \"red\"\n",
    "            elif (round(field[ii, jj] % 1.0, 1) == 0.4):\n",
    "                clr = \"lightgreen\"\n",
    "            elif (round(field[ii, jj] % 1.0, 1) == 0.6):\n",
    "                clr = \"cyan\"\n",
    "            else:\n",
    "                clr = \"purple\"\n",
    "\n",
    "            #if (field[ii, jj] // 1 == 1.0):\n",
    "            #    circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=4, radius=0.4, color=clr) )\n",
    "            #else:\n",
    "            #    circles.append( mpatches.Circle((jj + 1, 7 - ii), radius=0.4, color=clr) )\n",
    "             \n",
    "            #\n",
    "            # DEBUG\n",
    "            #\n",
    "            if (field[ii, jj] == 0.0):\n",
    "                circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=3, radius=0.2, color=\"black\") )\n",
    "            elif (field[ii, jj] // 1 == 1.0):\n",
    "                circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=4, radius=0.4, color=clr) )\n",
    "            else:\n",
    "                circles.append( mpatches.Circle((jj + 1, 7 - ii), radius=0.4, color=clr) )\n",
    "\n",
    "\n",
    "    for circ in circles:\n",
    "        ax.add_artist(circ)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_in_set(plate, row, col, length, direction):\n",
    "    \"\"\"\n",
    "    Checks whether plate is with the set given by row, col, length, direction\n",
    "    Input:\n",
    "    - plate: plate location, tuple (row, column)\n",
    "    - row: row where the set starts\n",
    "    - col: column where the set starts\n",
    "    - length: the set's length\n",
    "    - direction: the set's direction\n",
    "    Output:\n",
    "    - True if the plate is within the set, False otherwise\n",
    "    \"\"\"\n",
    "    if (direction == 0):\n",
    "        # Horizontal set\n",
    "        if ((plate[0] != row) or (plate[1] < col) or (plate[1] > (col + length - 1))):\n",
    "            return False\n",
    "    else:\n",
    "        # Vertucal set\n",
    "        if ((plate[1] != col) or (plate[0] < row) or (plate[0] > (row + length - 1))):\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_field(field, colors):\n",
    "    \"\"\"\n",
    "    Наполняет поле после сжигания рядов.\n",
    "    Сдвигает фишки вниз, заполняя верхний ряд каждый раз так, чтобы верхний ряд не создавал халявной тройки\n",
    "    Начинает с левого нижнего угла, чтобы переиспользовать color_fits()\n",
    "    Input:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    - colors: list of 4 floats - color values, see the definition above\n",
    "    Output:\n",
    "    - numpy array of floats, 7x6 - updated field\n",
    "    \"\"\"\n",
    "    for ii in list(range(7))[::-1]:\n",
    "        for jj in range(6):\n",
    "            while (field[ii, jj] == 0.):\n",
    "                # Опускаем на один вниз\n",
    "                # Если мы в самом верхнем ряду, то опускать не нужно\n",
    "                if (ii != 0):\n",
    "                    for iii in list(range(1, ii + 1))[::-1]:\n",
    "                        field[iii, jj] = field[iii - 1, jj]\n",
    "\n",
    "                # Заполняем верх\n",
    "                new_color = rd.choice(colors)\n",
    "\n",
    "                while not color_fits(field, 0, jj, new_color):\n",
    "                    new_color = rd.choice(colors)\n",
    "\n",
    "                field[0, jj] = new_color  \n",
    "                \n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move_v2(field, move, moves):\n",
    "    \"\"\"\n",
    "    Physically moves plates according to the move\n",
    "    Input:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    - move: particular move to make, 1<=move<=142\n",
    "    - moves: dictionary of all possible moves defined above\n",
    "    Output:\n",
    "    - new_field: updated field with two swapped plates\n",
    "    - plate_start: coordinates of the plate that started the move, tuple (row, column)\n",
    "    - plate_end: cooredinates of the plate that ended the move, tuple (row, column)\n",
    "    \"\"\"\n",
    "    (start_row, start_col), (end_row, end_col) = moves[move]\n",
    "\n",
    "    # Swap two plates and create new (modified) field\n",
    "    new_field = np.array(field)\n",
    "    temp_color = field[end_row, end_col]\n",
    "    new_field[end_row, end_col] = field[start_row, start_col]\n",
    "    new_field[start_row, start_col] = temp_color\n",
    "        \n",
    "    return new_field, (start_row, start_col), (end_row, end_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(field):\n",
    "    \"\"\"\n",
    "    Finds all sets and all bonus plates included into those sets\n",
    "    Input:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    Output:\n",
    "    - list of sets coordinates: list of tuples (row_start, column_start, set_length, direction, color), counting from top left corner\n",
    "      Direction is either 0 (horizontal) or 1 (vertical)\n",
    "    - list of bonus plates included into sets: list of tuples (row, column, type). \n",
    "      Type is either 4 or 5 (reserved for future)\n",
    "    \"\"\"\n",
    "    perm_bonus_plates = []\n",
    "    perm_sets = []\n",
    "\n",
    "    # Find all 3+ sets in horizontal row\n",
    "    for ii in range(field.shape[0]):\n",
    "        temp_bonus_plates = []\n",
    "        jj = 0\n",
    "        len = 1\n",
    "        while (jj < field.shape[1]):\n",
    "            if (jj > 0):\n",
    "                if (round(field[ii, jj] % 1.0, 1) == round(field[ii, jj - 1] % 1.0, 1)):\n",
    "                    len = len + 1\n",
    "                else:\n",
    "                    if (len >= 3):\n",
    "                        # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "                        perm_bonus_plates = perm_bonus_plates + temp_bonus_plates\n",
    "                        \n",
    "                        # Add to permanent list of sets\n",
    "                        perm_sets.append((ii, jj - len, len, 0, round(field[ii, jj - 1] % 1, 1)))\n",
    "                        \n",
    "                    temp_bonus_plates = []\n",
    "                    len = 1\n",
    "            \n",
    "            if (field[ii, jj] > 1.):\n",
    "                # Add to temp list of bonus plates\n",
    "                temp_bonus_plates.append((ii, jj, 4))\n",
    "            \n",
    "            jj = jj + 1\n",
    "            \n",
    "        if (len >= 3):\n",
    "            # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "            perm_bonus_plates = perm_bonus_plates + temp_bonus_plates\n",
    "\n",
    "            # Add to permanent list of sets\n",
    "            perm_sets.append((ii, jj - len, len, 0, round(field[ii, jj - 1] % 1, 1)))\n",
    "\n",
    "    # Find all 3+ sets in vertical columns\n",
    "    for jj in range(field.shape[1]):\n",
    "        temp_bonus_plates = []\n",
    "        ii = 0\n",
    "        len = 1\n",
    "        while (ii < field.shape[0]):\n",
    "            if (ii > 0):\n",
    "                if (round(field[ii, jj] % 1.0, 1) == round(field[ii - 1, jj] % 1, 1)):\n",
    "                    len = len + 1\n",
    "                else:\n",
    "                    if (len >= 3):\n",
    "                        # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "                        perm_bonus_plates = perm_bonus_plates + temp_bonus_plates\n",
    "                        \n",
    "                        # Add to permanent list of sets\n",
    "                        perm_sets.append((ii - len, jj, len, 1, round(field[ii - 1, jj] % 1, 1)))\n",
    "                        \n",
    "                    temp_bonus_plates = []\n",
    "                    len = 1\n",
    "            \n",
    "            if (field[ii, jj] > 1.):\n",
    "                # Add to temp list of bonus plates\n",
    "                temp_bonus_plates.append((ii, jj, 4))\n",
    "            \n",
    "            ii = ii + 1\n",
    "            \n",
    "        if (len >= 3):\n",
    "            # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "            perm_bonus_plates = perm_bonus_plates + temp_bonus_plates\n",
    "\n",
    "            # Add to permanent list of sets\n",
    "            perm_sets.append((ii - len, jj, len, 1, round(field[ii - 1, jj] % 1, 1)))\n",
    "            \n",
    "    return perm_sets, perm_bonus_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_v2(field, plate_from, plate_to):\n",
    "    \"\"\"\n",
    "    Calculates the score in the field. \n",
    "    Replaces all sets with zeros.\n",
    "    Handles bonus plates: replaces required rows with zeros (Type 4)\n",
    "    Puts bonus plates, should any set be of the length of 4\n",
    "    Input:\n",
    "    - field: numpy array of floats, 7x6\n",
    "    - plate_from: coordinates of the plate where the move starts, tuple (row, column)\n",
    "    - plate_to: coordinates of the plate where the move ends, tuple (row, column)\n",
    "    Output:\n",
    "    - score: int, 0+\n",
    "    - field: modified field\n",
    "    \"\"\"\n",
    "    # Get all sets with possible bonus plates\n",
    "    sets, bonus_plates = get_sets(field)\n",
    "\n",
    "    # Set all requires plates to zero\n",
    "    #\n",
    "    # First handle sets\n",
    "    for st in sets:\n",
    "        row = st[0]\n",
    "        col = st[1]\n",
    "        lng = st[2]\n",
    "        drc = st[3]\n",
    "\n",
    "        if (drc == 0):\n",
    "            field[row, col:(col + lng)] = 0\n",
    "        else:\n",
    "            field[row:(row + lng), col] = 0\n",
    "    #       \n",
    "    # Then handle bonus plates/rows\n",
    "    for pl in bonus_plates:\n",
    "        row = pl[0]\n",
    "        col = pl[1]\n",
    "        typ = pl[2]\n",
    "\n",
    "        if (typ == 4):\n",
    "            field[row, :] = 0\n",
    "\n",
    "    # Calculate score\n",
    "    score = (field == 0.).sum()\n",
    "\n",
    "    # Put new bonus plates. Specially care for the move coordinates\n",
    "    for st in sets:\n",
    "        row = st[0]\n",
    "        col = st[1]\n",
    "        lng = st[2]\n",
    "        drc = st[3]\n",
    "        clr = st[4]\n",
    "\n",
    "        if (lng >= 4):\n",
    "            if (plate_in_set(plate_from, row, col, lng, drc)):\n",
    "                # Move start plate in set. Put new bonus plate according to the move coordinates\n",
    "                field[plate_from[0], plate_from[1]] = clr + 1.0\n",
    "                \n",
    "                #\n",
    "                # DEBUG\n",
    "                #\n",
    "                #print(\"DEBUG: set of 4+ was made!\")\n",
    "                \n",
    "            elif (plate_in_set(plate_to, row, col, lng, drc)):\n",
    "                # Move end plate in set. Put new bonus plate according to the move coordinates\n",
    "                field[plate_to[0], plate_to[1]] = clr + 1.0\n",
    "                \n",
    "                #\n",
    "                # DEBUG\n",
    "                #\n",
    "                #print(\"DEBUG: set of 4+ was made!\")\n",
    "                \n",
    "            else:\n",
    "                # Just put the new bonus plate at the very right/bottom of the set\n",
    "                # This CANNOT happen during the manual move!\n",
    "                # It CAN ONLY HAPPEN when the field is randomly filled with new plates\n",
    "                if (drc == 0):\n",
    "                    field[row, col + lng - 1] = clr + 1.0\n",
    "                else:\n",
    "                    field[row + lng - 1, col] = clr + 1.0\n",
    "\n",
    "    return score, field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Replay memory buffer\n",
    "#\n",
    "class ExperienceBuffer():\n",
    "    '''\n",
    "    Experience Replay Buffer\n",
    "    Inspired by Andrea Lonza\n",
    "    '''\n",
    "\n",
    "    def __init__(self, buffer_size, gamma):\n",
    "        # Constants\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Main Replay Memory buffer parts\n",
    "        self.states_before = deque(maxlen=buffer_size)\n",
    "        self.actions = deque(maxlen=buffer_size)\n",
    "        self.total_rewards = deque(maxlen=buffer_size)\n",
    "        self.states_after = deque(maxlen=buffer_size)\n",
    "        self.last_moves = deque(maxlen=buffer_size)\n",
    "   \n",
    "    \n",
    "    def add(self, state_before, action, reward, state_after, last_move):\n",
    "        # Add certain items to corresponding buffers\n",
    "        self.states_before.append(state_before)\n",
    "        self.actions.append(action)\n",
    "\n",
    "        self.total_rewards.append(reward)\n",
    "        self.states_after.append(state_after)\n",
    "        self.last_moves.append(last_move)\n",
    "    \n",
    "    \n",
    "    def sample_minibatch(self, minibatch_size):\n",
    "        '''\n",
    "        Sample a minibatch of size batch_size\n",
    "        Note1: always add the most recent completed move\n",
    "        '''\n",
    "        indices = rd.sample(range(len(self.states_before) - 1), minibatch_size - 1)\n",
    "        # Add the most recent completed move index\n",
    "        indices.append(len(self.states_before) - 1)\n",
    "        \n",
    "        minibatch_states_before = np.array([self.states_before[i] for i in indices]) \n",
    "        minibatch_actions = np.array([self.actions[i] for i in indices]) \n",
    "        minibatch_total_rewards = np.array([self.total_rewards[i] for i in indices]) \n",
    "        minibatch_states_after = np.array([self.states_after[i] for i in indices])  \n",
    "        minibatch_last_moves = np.array([self.last_moves[i] for i in indices])   \n",
    "        \n",
    "        return minibatch_states_before, minibatch_actions, minibatch_total_rewards, minibatch_states_after, minibatch_last_moves\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return length of the current replay memory buffer\n",
    "        Relevant for the first *minibatch_size* moves.\n",
    "        '''\n",
    "        return len(self.states_before)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-Nework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AeroCNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AeroCNN, self).__init__()\n",
    "        \n",
    "        self.gamma = GAMMA\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        \n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate)      \n",
    "        \n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(7, 6, 1))\n",
    "        \n",
    "        self.hidden_layers = [] \n",
    "        self.hidden_layers.append(Conv2D(192, kernel_size=3, strides = (1, 1), padding='same', activation='relu', data_format = 'channels_last'))\n",
    "        self.hidden_layers.append(Conv2D(128, kernel_size=3, strides = (1, 1), padding='same', activation='relu'))    \n",
    "        self.hidden_layers.append(Flatten())                      \n",
    "                                  \n",
    "        self.output_layer = tf.keras.layers.Dense(142, activation='relu', kernel_initializer='RandomNormal')\n",
    "\n",
    "                                  \n",
    "    # Define model forward pass\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        z = self.input_layer(inputs)\n",
    "                                  \n",
    "        for layer in self.hidden_layers:\n",
    "            z = layer(z)\n",
    "                                  \n",
    "        output = self.output_layer(z)\n",
    "                                  \n",
    "        return output\n",
    "                   \n",
    "        \n",
    "    def train(self, s_before, actions, rewards, s_after, dones, TargetNet):\n",
    "        \n",
    "        rewards_next = np.max(TargetNet.predict(s_after), axis=1)\n",
    "        actual_values = np.where(dones, rewards, rewards + self.gamma*rewards_next)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self.call(s_before)\n",
    "            \n",
    "            selected_action_values = tf.math.reduce_sum(prediction*tf.one_hot(actions, 142), axis=1)  \n",
    "            \n",
    "            loss = tf.math.reduce_mean(tf.square(actual_values - selected_action_values))\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        \n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ExperienceBuffer(REPLAY_MEMORY_SIZE, GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Online CNN and Target CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_online = AeroCNN()  \n",
    "cnn_target = AeroCNN()\n",
    "\n",
    "cnn_target.set_weights(cnn_online.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games: 500, last 100 games avg score: 58.226, avg of successful moves: 8.866, loss 6396805105319936.0\n",
      "CNN made 4950 moves. Successful were 485\n",
      "Games: 1000, last 100 games avg score: 58.464, avg of successful moves: 9.056, loss 5832553239937024.0\n",
      "CNN made 5061 moves. Successful were 538\n",
      "Games: 1500, last 100 games avg score: 57.228, avg of successful moves: 8.672, loss 7873952806338560.0\n",
      "CNN made 4967 moves. Successful were 451\n",
      "Games: 2000, last 100 games avg score: 57.57, avg of successful moves: 8.888, loss 8459367586201600.0\n",
      "CNN made 5039 moves. Successful were 520\n",
      "Games: 2500, last 100 games avg score: 58.254, avg of successful moves: 8.712, loss 9528447223201792.0\n",
      "CNN made 4949 moves. Successful were 469\n",
      "Games: 3000, last 100 games avg score: 57.296, avg of successful moves: 8.628, loss 8885053606068224.0\n",
      "CNN made 4991 moves. Successful were 445\n",
      "Games: 3500, last 100 games avg score: 56.34, avg of successful moves: 8.484, loss 1.0495594401366016e+16\n",
      "CNN made 5009 moves. Successful were 436\n",
      "Games: 4000, last 100 games avg score: 58.812, avg of successful moves: 8.812, loss 9484161815412736.0\n",
      "CNN made 5020 moves. Successful were 481\n",
      "Games: 4500, last 100 games avg score: 56.332, avg of successful moves: 8.596, loss 8476459408556032.0\n",
      "CNN made 4893 moves. Successful were 428\n",
      "Games: 5000, last 100 games avg score: 57.5, avg of successful moves: 8.762, loss 1.1006443180261376e+16\n",
      "CNN made 4954 moves. Successful were 476\n",
      "Games: 5500, last 100 games avg score: 57.878, avg of successful moves: 8.788, loss 9306895630204928.0\n",
      "CNN made 4993 moves. Successful were 455\n",
      "Games: 6000, last 100 games avg score: 59.026, avg of successful moves: 8.924, loss 1.1933248804356096e+16\n",
      "CNN made 5029 moves. Successful were 503\n",
      "Games: 6500, last 100 games avg score: 58.814, avg of successful moves: 8.892, loss 1.3170230524116992e+16\n",
      "CNN made 5004 moves. Successful were 477\n",
      "Games: 7000, last 100 games avg score: 59.144, avg of successful moves: 8.862, loss 8476921117540352.0\n",
      "CNN made 5001 moves. Successful were 495\n",
      "Games: 7500, last 100 games avg score: 58.744, avg of successful moves: 8.968, loss 1.2993008362323968e+16\n",
      "CNN made 5063 moves. Successful were 503\n",
      "Games: 8000, last 100 games avg score: 58.564, avg of successful moves: 8.822, loss 9643644688531456.0\n",
      "CNN made 4996 moves. Successful were 467\n",
      "Games: 8500, last 100 games avg score: 60.434, avg of successful moves: 9.106, loss 9221438665916416.0\n",
      "CNN made 4962 moves. Successful were 487\n",
      "Games: 9000, last 100 games avg score: 59.036, avg of successful moves: 8.914, loss 9332675097657344.0\n",
      "CNN made 5017 moves. Successful were 495\n",
      "Games: 9500, last 100 games avg score: 59.05, avg of successful moves: 8.91, loss 1.1635429329600512e+16\n",
      "CNN made 4935 moves. Successful were 504\n",
      "Games: 10000, last 100 games avg score: 58.664, avg of successful moves: 8.864, loss 1.2802832579166208e+16\n",
      "CNN made 5047 moves. Successful were 477\n",
      "Games: 10500, last 100 games avg score: 58.704, avg of successful moves: 8.658, loss 1.1720942128463872e+16\n",
      "CNN made 5029 moves. Successful were 483\n",
      "Games: 11000, last 100 games avg score: 59.22, avg of successful moves: 8.944, loss 1.0800348100820992e+16\n",
      "CNN made 4997 moves. Successful were 512\n",
      "Games: 11500, last 100 games avg score: 57.646, avg of successful moves: 8.676, loss 1.902060841520333e+16\n",
      "CNN made 5070 moves. Successful were 487\n",
      "Games: 12000, last 100 games avg score: 59.922, avg of successful moves: 8.866, loss 1.624135440531456e+16\n",
      "CNN made 4946 moves. Successful were 484\n",
      "Games: 12500, last 100 games avg score: 56.948, avg of successful moves: 8.5, loss 1.332233893838848e+16\n",
      "CNN made 4953 moves. Successful were 431\n",
      "Games: 13000, last 100 games avg score: 58.074, avg of successful moves: 8.756, loss 1.6828600988729344e+16\n",
      "CNN made 4954 moves. Successful were 482\n",
      "Games: 13500, last 100 games avg score: 58.332, avg of successful moves: 8.908, loss 1.5840069168398336e+16\n",
      "CNN made 4984 moves. Successful were 514\n",
      "Games: 14000, last 100 games avg score: 60.114, avg of successful moves: 9.014, loss 1.6668849680154624e+16\n",
      "CNN made 5063 moves. Successful were 540\n",
      "Games: 14500, last 100 games avg score: 59.726, avg of successful moves: 8.854, loss 1.6199425860829184e+16\n",
      "CNN made 4916 moves. Successful were 448\n",
      "Games: 15000, last 100 games avg score: 56.714, avg of successful moves: 8.666, loss 1.7054850202206208e+16\n",
      "CNN made 5076 moves. Successful were 537\n",
      "Games: 15500, last 100 games avg score: 55.236, avg of successful moves: 8.714, loss 2.2102520180506624e+16\n",
      "CNN made 4982 moves. Successful were 482\n",
      "Games: 16000, last 100 games avg score: 58.808, avg of successful moves: 8.954, loss 3.833566690331853e+16\n",
      "CNN made 4983 moves. Successful were 510\n",
      "Games: 16500, last 100 games avg score: 57.838, avg of successful moves: 8.8, loss 4.463636674668134e+16\n",
      "CNN made 5074 moves. Successful were 496\n",
      "Games: 17000, last 100 games avg score: 58.602, avg of successful moves: 8.856, loss 4.704705458051482e+16\n",
      "CNN made 4934 moves. Successful were 455\n",
      "Games: 17500, last 100 games avg score: 57.018, avg of successful moves: 8.748, loss 3.752839344029696e+16\n",
      "CNN made 5047 moves. Successful were 414\n",
      "Games: 18000, last 100 games avg score: 57.27, avg of successful moves: 8.604, loss 4.947998175500698e+16\n",
      "CNN made 4992 moves. Successful were 433\n",
      "Games: 18500, last 100 games avg score: 55.9, avg of successful moves: 8.532, loss 4.684460270708326e+16\n",
      "CNN made 5043 moves. Successful were 449\n",
      "Games: 19000, last 100 games avg score: 57.778, avg of successful moves: 8.492, loss 3.66739698262999e+16\n",
      "CNN made 4946 moves. Successful were 424\n",
      "Games: 19500, last 100 games avg score: 58.474, avg of successful moves: 8.782, loss 4.303731176767488e+16\n",
      "CNN made 5022 moves. Successful were 446\n",
      "Games: 20000, last 100 games avg score: 57.79, avg of successful moves: 8.828, loss 4.030620648865792e+16\n",
      "CNN made 5013 moves. Successful were 457\n",
      "Games: 20500, last 100 games avg score: 57.64, avg of successful moves: 8.754, loss 3.012763650831155e+16\n",
      "CNN made 5048 moves. Successful were 449\n",
      "Games: 21000, last 100 games avg score: 55.636, avg of successful moves: 8.466, loss 2.681327681798144e+16\n",
      "CNN made 5058 moves. Successful were 397\n",
      "Games: 21500, last 100 games avg score: 58.43, avg of successful moves: 8.822, loss 3.484387567153971e+16\n",
      "CNN made 4957 moves. Successful were 464\n",
      "Games: 22000, last 100 games avg score: 58.416, avg of successful moves: 8.768, loss 2.6151106677571584e+16\n",
      "CNN made 4997 moves. Successful were 460\n",
      "Games: 22500, last 100 games avg score: 58.982, avg of successful moves: 8.956, loss 2.5141477977882624e+16\n",
      "CNN made 5030 moves. Successful were 529\n",
      "Games: 23000, last 100 games avg score: 60.216, avg of successful moves: 8.914, loss 1.9590436758749184e+16\n",
      "CNN made 4942 moves. Successful were 522\n",
      "Games: 23500, last 100 games avg score: 60.19, avg of successful moves: 8.884, loss 1.995022187416781e+16\n",
      "CNN made 5008 moves. Successful were 533\n",
      "Games: 24000, last 100 games avg score: 59.528, avg of successful moves: 9.09, loss 2.343284549825331e+16\n",
      "CNN made 5025 moves. Successful were 554\n",
      "Games: 24500, last 100 games avg score: 60.572, avg of successful moves: 9.044, loss 3.248791431099187e+16\n",
      "CNN made 5134 moves. Successful were 554\n",
      "Games: 25000, last 100 games avg score: 59.746, avg of successful moves: 8.902, loss 3.235249399214899e+16\n",
      "CNN made 5014 moves. Successful were 499\n",
      "Games: 25500, last 100 games avg score: 58.08, avg of successful moves: 8.786, loss 4.043549788916941e+16\n",
      "CNN made 4892 moves. Successful were 451\n",
      "Games: 26000, last 100 games avg score: 60.332, avg of successful moves: 8.97, loss 3.805138301799629e+16\n",
      "CNN made 4987 moves. Successful were 477\n",
      "Games: 26500, last 100 games avg score: 56.23, avg of successful moves: 8.716, loss 3.692053530882867e+16\n",
      "CNN made 4864 moves. Successful were 471\n",
      "Games: 27000, last 100 games avg score: 57.712, avg of successful moves: 8.792, loss 4.377518285416038e+16\n",
      "CNN made 5023 moves. Successful were 480\n",
      "Games: 27500, last 100 games avg score: 59.366, avg of successful moves: 8.954, loss 4.483523232242074e+16\n",
      "CNN made 5018 moves. Successful were 463\n",
      "Games: 28000, last 100 games avg score: 57.168, avg of successful moves: 8.874, loss 5.039432016278323e+16\n",
      "CNN made 5001 moves. Successful were 488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games: 28500, last 100 games avg score: 59.056, avg of successful moves: 8.902, loss 5.093043945550643e+16\n",
      "CNN made 4960 moves. Successful were 498\n",
      "Games: 29000, last 100 games avg score: 59.868, avg of successful moves: 8.948, loss 4.427193018168115e+16\n",
      "CNN made 4861 moves. Successful were 479\n",
      "Games: 29500, last 100 games avg score: 60.0, avg of successful moves: 8.92, loss 3.67458074492928e+16\n",
      "CNN made 4921 moves. Successful were 519\n",
      "Games: 30000, last 100 games avg score: 58.418, avg of successful moves: 8.748, loss 2.511508755133235e+16\n",
      "CNN made 5066 moves. Successful were 451\n",
      "Games: 30500, last 100 games avg score: 59.116, avg of successful moves: 8.92, loss 2.7822321402118144e+16\n",
      "CNN made 4980 moves. Successful were 477\n",
      "Games: 31000, last 100 games avg score: 56.452, avg of successful moves: 8.702, loss 2.367649899295539e+16\n",
      "CNN made 5077 moves. Successful were 442\n",
      "Games: 31500, last 100 games avg score: 56.688, avg of successful moves: 8.626, loss 2.061875071365939e+16\n",
      "CNN made 5149 moves. Successful were 422\n",
      "Games: 32000, last 100 games avg score: 59.112, avg of successful moves: 8.916, loss 1.173149378936832e+16\n",
      "CNN made 5035 moves. Successful were 470\n",
      "Games: 32500, last 100 games avg score: 55.922, avg of successful moves: 8.6, loss 1.0991222889906176e+16\n",
      "CNN made 4976 moves. Successful were 424\n",
      "Games: 33000, last 100 games avg score: 58.346, avg of successful moves: 8.894, loss 7007866208649216.0\n",
      "CNN made 5037 moves. Successful were 509\n",
      "Games: 33500, last 100 games avg score: 58.192, avg of successful moves: 8.774, loss 6669665988247552.0\n",
      "CNN made 4906 moves. Successful were 474\n",
      "Games: 34000, last 100 games avg score: 57.27, avg of successful moves: 8.85, loss 7913755342012416.0\n",
      "CNN made 4822 moves. Successful were 453\n",
      "Games: 34500, last 100 games avg score: 56.418, avg of successful moves: 8.712, loss 1.0745370371948544e+16\n",
      "CNN made 5018 moves. Successful were 444\n",
      "Games: 35000, last 100 games avg score: 57.072, avg of successful moves: 8.7, loss 1.1866206512349184e+16\n",
      "CNN made 5039 moves. Successful were 438\n",
      "Games: 35500, last 100 games avg score: 53.892, avg of successful moves: 8.426, loss 1.797709027606528e+16\n",
      "CNN made 5032 moves. Successful were 392\n",
      "Games: 36000, last 100 games avg score: 56.132, avg of successful moves: 8.684, loss 2.5256830062034944e+16\n",
      "CNN made 4944 moves. Successful were 436\n",
      "Games: 36500, last 100 games avg score: 54.832, avg of successful moves: 8.674, loss 2.114144823358259e+16\n",
      "CNN made 4921 moves. Successful were 417\n",
      "Games: 37000, last 100 games avg score: 57.462, avg of successful moves: 8.614, loss 3.858551374086144e+16\n",
      "CNN made 4964 moves. Successful were 459\n",
      "Games: 37500, last 100 games avg score: 57.046, avg of successful moves: 8.772, loss 3.2500988191440896e+16\n",
      "CNN made 4997 moves. Successful were 474\n",
      "Games: 38000, last 100 games avg score: 58.426, avg of successful moves: 8.91, loss 4.88377552952361e+16\n",
      "CNN made 4994 moves. Successful were 518\n",
      "Games: 38500, last 100 games avg score: 58.092, avg of successful moves: 8.778, loss 4.023225574175539e+16\n",
      "CNN made 5013 moves. Successful were 526\n",
      "Games: 39000, last 100 games avg score: 57.084, avg of successful moves: 8.678, loss 5.029672991588352e+16\n",
      "CNN made 4944 moves. Successful were 474\n",
      "Games: 39500, last 100 games avg score: 59.94, avg of successful moves: 8.92, loss 4.285759745110835e+16\n",
      "CNN made 4996 moves. Successful were 510\n",
      "Games: 40000, last 100 games avg score: 60.122, avg of successful moves: 8.992, loss 5.105980816542925e+16\n",
      "CNN made 5041 moves. Successful were 538\n",
      "Games: 40500, last 100 games avg score: 60.362, avg of successful moves: 9.128, loss 2.8650410424139776e+16\n",
      "CNN made 5043 moves. Successful were 563\n",
      "Games: 41000, last 100 games avg score: 59.822, avg of successful moves: 9.178, loss 3.93189266512937e+16\n",
      "CNN made 5001 moves. Successful were 544\n",
      "Games: 41500, last 100 games avg score: 56.82, avg of successful moves: 8.606, loss 4.546592250003456e+16\n",
      "CNN made 5090 moves. Successful were 478\n",
      "Games: 42000, last 100 games avg score: 55.956, avg of successful moves: 8.628, loss 4.625447849558016e+16\n",
      "CNN made 4979 moves. Successful were 413\n",
      "Games: 42500, last 100 games avg score: 57.992, avg of successful moves: 8.898, loss 4.532614278938624e+16\n",
      "CNN made 5067 moves. Successful were 468\n",
      "Games: 43000, last 100 games avg score: 57.224, avg of successful moves: 8.85, loss 5.76320143664087e+16\n",
      "CNN made 4981 moves. Successful were 447\n",
      "Games: 43500, last 100 games avg score: 57.688, avg of successful moves: 8.968, loss 6.616984241517363e+16\n",
      "CNN made 4921 moves. Successful were 454\n",
      "Games: 44000, last 100 games avg score: 59.634, avg of successful moves: 8.832, loss 9.444284332559565e+16\n",
      "CNN made 5010 moves. Successful were 477\n",
      "Games: 44500, last 100 games avg score: 58.584, avg of successful moves: 8.93, loss 8.091328402633523e+16\n",
      "CNN made 4913 moves. Successful were 476\n",
      "Games: 45000, last 100 games avg score: 58.058, avg of successful moves: 8.768, loss 9.788378214458982e+16\n",
      "CNN made 5025 moves. Successful were 493\n",
      "Games: 45500, last 100 games avg score: 55.522, avg of successful moves: 8.576, loss 1.799142387042222e+17\n",
      "CNN made 5024 moves. Successful were 449\n",
      "Games: 46000, last 100 games avg score: 57.794, avg of successful moves: 8.686, loss 1.683696930300887e+17\n",
      "CNN made 4978 moves. Successful were 473\n",
      "Games: 46500, last 100 games avg score: 54.498, avg of successful moves: 8.368, loss 1.86173105566122e+17\n",
      "CNN made 5000 moves. Successful were 416\n",
      "Games: 47000, last 100 games avg score: 59.642, avg of successful moves: 8.97, loss 2.3674897399650714e+17\n",
      "CNN made 4977 moves. Successful were 471\n",
      "Games: 47500, last 100 games avg score: 58.348, avg of successful moves: 8.766, loss 2.3209589232736666e+17\n",
      "CNN made 5106 moves. Successful were 513\n",
      "Games: 48000, last 100 games avg score: 58.46, avg of successful moves: 8.872, loss 2.4290343879337574e+17\n",
      "CNN made 4966 moves. Successful were 500\n",
      "Games: 48500, last 100 games avg score: 57.842, avg of successful moves: 8.796, loss 2.2246142168897946e+17\n",
      "CNN made 5034 moves. Successful were 518\n",
      "Games: 49000, last 100 games avg score: 57.842, avg of successful moves: 8.98, loss 3.114463580137718e+17\n",
      "CNN made 4944 moves. Successful were 522\n",
      "Games: 49500, last 100 games avg score: 58.466, avg of successful moves: 8.748, loss 2.5913623332886938e+17\n",
      "CNN made 4909 moves. Successful were 454\n",
      "Games: 50000, last 100 games avg score: 58.156, avg of successful moves: 8.81, loss 3.214620155896136e+17\n",
      "CNN made 5094 moves. Successful were 471\n",
      "Games: 50500, last 100 games avg score: 60.726, avg of successful moves: 9.09, loss 3.053281599207506e+17\n",
      "CNN made 4999 moves. Successful were 502\n",
      "Games: 51000, last 100 games avg score: 61.52, avg of successful moves: 9.266, loss 2.58334345754837e+17\n",
      "CNN made 5037 moves. Successful were 552\n",
      "Games: 51500, last 100 games avg score: 60.262, avg of successful moves: 8.844, loss 2.572523232338903e+17\n",
      "CNN made 5053 moves. Successful were 548\n",
      "Games: 52000, last 100 games avg score: 58.76, avg of successful moves: 8.902, loss 2.779934762205184e+17\n",
      "CNN made 5020 moves. Successful were 508\n",
      "Games: 52500, last 100 games avg score: 59.756, avg of successful moves: 8.942, loss 2.4833871990646374e+17\n",
      "CNN made 4988 moves. Successful were 525\n",
      "Games: 53000, last 100 games avg score: 56.046, avg of successful moves: 8.684, loss 2.0724900830380032e+17\n",
      "CNN made 4980 moves. Successful were 491\n",
      "Games: 53500, last 100 games avg score: 59.712, avg of successful moves: 8.864, loss 2.280917630367826e+17\n",
      "CNN made 5007 moves. Successful were 515\n",
      "Games: 54000, last 100 games avg score: 59.432, avg of successful moves: 8.878, loss 1.899489143952507e+17\n",
      "CNN made 5076 moves. Successful were 492\n",
      "Games: 54500, last 100 games avg score: 57.612, avg of successful moves: 8.89, loss 2.0754020708646912e+17\n",
      "CNN made 5112 moves. Successful were 476\n",
      "Games: 55000, last 100 games avg score: 58.64, avg of successful moves: 8.89, loss 1.8067592538436403e+17\n",
      "CNN made 5087 moves. Successful were 534\n",
      "Games: 55500, last 100 games avg score: 58.262, avg of successful moves: 8.946, loss 2.4110352107883725e+17\n",
      "CNN made 4962 moves. Successful were 504\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Number of moves made to follow the target CNN update strategy\n",
    "total_moves = 1\n",
    "\n",
    "# Initialize TensorBoard\n",
    "#tensorboard_callback = TensorBoard(log_dir='./logs', profile_batch=5, histogram_freq=0)\n",
    "                                                      \n",
    "for game in range(GAMES_TO_PLAY):\n",
    "    # Start one game\n",
    "    game_score = 0\n",
    "    successful_moves = 0\n",
    "\n",
    "    # Initialize the game field\n",
    "    field = np.zeros((7, 6))\n",
    "    field = initialize_field(field)\n",
    "\n",
    "    for m in range(NUMBER_OF_MOVES_IN_GAME):\n",
    "        # Total score of one move\n",
    "        reward = 0\n",
    "\n",
    "        # Whether CNN made the move\n",
    "        cnn_made_move_flag = False\n",
    "        \n",
    "        # If replay_memory has less than 64 moves, then make a random move\n",
    "        if ((len(replay_memory) < MINIBATCH_SIZE) or (rd.random() > CNN_MOVE_PROB)):\n",
    "            move = rd.randint(1, 142)\n",
    "        else:\n",
    "            # CNN selects a move\n",
    "            cnn_made_move_flag = True\n",
    "            X_data = np.expand_dims(np.expand_dims(field, axis=0), axis=3)\n",
    "            move = cnn_target.predict(X_data).argmax() + 1\n",
    "\n",
    "        # Make the move\n",
    "        s_before = field\n",
    "        new_field, plate_a, plate_b = make_move_v2(field, move, moves)\n",
    "\n",
    "        # Calculate the score and update the field\n",
    "        score, new_field = calculate_score_v2(new_field, plate_a, plate_b)\n",
    "        \n",
    "        # Если ход результативный, то обновляем поле и проверяем, получились ли новые цветовые ряды\n",
    "        # Пока есть новые цветные ряды, обрабатываем их, обсчитываем и сдвигаем блюда\n",
    "        successful_move_flag = False\n",
    "\n",
    "        while (score > 0.):\n",
    "            if (not successful_move_flag):\n",
    "                successful_moves = successful_moves + 1\n",
    "                successful_move_flag = True\n",
    "\n",
    "            # Суммируем набранные очки\n",
    "            reward = reward + score\n",
    "\n",
    "            # Сдвигаем фишки вниз, заполняя верхний ряд каждый раз так, чтобы верхний ряд не создавал халявной тройки\n",
    "            # Начинаем с левого нижнего угла (чтобы переиспользовать color_fits())\n",
    "            new_field = fill_field(new_field, colors)\n",
    "\n",
    "            # Считаем очки и обрабатываем новые возможные цветные ряды\n",
    "            score, new_field = calculate_score_v2(new_field, (-1, -1), (-1, -1))\n",
    "\n",
    "        # Увеличиваем счет игры\n",
    "        game_score = game_score + reward\n",
    "        \n",
    "        # Update CNN move statistics\n",
    "        if (cnn_made_move_flag):\n",
    "            if (successful_move_flag):\n",
    "                CNN_SUCCESSFUL_PREDICTION = CNN_SUCCESSFUL_PREDICTION + 1\n",
    "                \n",
    "            CNN_MOVES_COUNT = CNN_MOVES_COUNT + 1\n",
    "            \n",
    "        # Check whether it's the last move of the current game\n",
    "        last_move = m == NUMBER_OF_MOVES_IN_GAME - 1\n",
    "        \n",
    "        #\n",
    "        # Train CNN based on the score\n",
    "        #\n",
    "        if (len(replay_memory) >= MINIBATCH_SIZE):\n",
    "            # Select random MINIBATCH_SIZE moves from replay memory buffer\n",
    "            samples = replay_memory.sample_minibatch(MINIBATCH_SIZE)\n",
    "\n",
    "            # Prepare some things for training\n",
    "            S_before = np.expand_dims(samples[0], axis=3)\n",
    "            S_after = np.expand_dims(samples[3], axis=3)            \n",
    "\n",
    "            # Update online CNN weights: training step\n",
    "            loss = cnn_online.train(S_before, samples[1], samples[2], S_after, samples[4], cnn_target)\n",
    "        \n",
    "        # Add new move to the replay memory\n",
    "        replay_memory.add(field, move, reward, new_field, last_move)\n",
    "\n",
    "        # If move is successful, update the play field\n",
    "        if (successful_move_flag):\n",
    "            field = new_field\n",
    "            \n",
    "        # After each 1000 moves update target CNN\n",
    "        if (total_moves % UPDATE_TARGET_NET == 0):\n",
    "            cnn_target.set_weights(cnn_online.get_weights())\n",
    "            \n",
    "        total_moves = total_moves + 1\n",
    "\n",
    "    #\n",
    "    # Calculate and display overall stats\n",
    "    #\n",
    "    # Проверяем, не обновили ли максимум\n",
    "    if (game_score > MAXIMUM_SCORE):\n",
    "        print(f\"New maximum: {game_score}, after {game} games.\")\n",
    "        MAXIMUM_SCORE = game_score\n",
    "        \n",
    "    # After each 500 games output average game score, average number of successful moves per game\n",
    "    TOTAL_SCORE_100 = TOTAL_SCORE_100 + game_score\n",
    "    TOTAL_SUCCESSFUL_MOVES_100 = TOTAL_SUCCESSFUL_MOVES_100 + successful_moves\n",
    "    \n",
    "    if ((game % 500 == 0) and (game > 0)):\n",
    "        avg_score = TOTAL_SCORE_100 / 500\n",
    "        #AVG_SCORE_HIST.append(avg_score)\n",
    "        TOTAL_SCORE_100 = 0.0\n",
    "        \n",
    "        avg_succ_moves = TOTAL_SUCCESSFUL_MOVES_100 / 500\n",
    "        AVG_SUCC_MOVES_HIST.append(avg_succ_moves)\n",
    "        TOTAL_SUCCESSFUL_MOVES_100 = 0.0\n",
    "\n",
    "        print(f\"Games: {game}, last 100 games avg score: {avg_score}, avg of successful moves: {avg_succ_moves}, loss {loss}\")        \n",
    "        print(f\"CNN made {CNN_MOVES_COUNT} moves. Successful were {CNN_SUCCESSFUL_PREDICTION}\")\n",
    "        \n",
    "        if (CNN_SUCCESSFUL_PREDICTION / CNN_MOVES_COUNT >= CNN_MOVE_PROB):\n",
    "            CNN_MOVE_PROB = CNN_MOVE_PROB + 0.1\n",
    "            \n",
    "        CNN_MOVES_COUNT = 0\n",
    "        CNN_SUCCESSFUL_PREDICTION = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    }
   ],
   "source": [
    "# tensorboard --logdir=./logs --bind_all &\n",
    "\n",
    "print(MAXIMUM_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field = np.zeros((7, 6))\n",
    "\n",
    "df = pd.DataFrame(updated_field)\n",
    "qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_df = qgrid_widget.get_changed_df()\n",
    "updated_field = updated_df.values\n",
    "visualize_field(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sets(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, new_field = calculate_score_v2(updated_field, (6, 3), (5, 3))\n",
    "print(score)\n",
    "visualize_field(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_field_2 = fill_field(updated_field, colors)\n",
    "#visualize_field(updated_field_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the CNN has been trained.\n",
    "### Start the long reinforcement-learning cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "successful_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_field = make_move(field, move)\n",
    "print(new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_field = calculate_score(new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_field = np.multiply(new_field, 1.0 - temp_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_field(new_field, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save model\n",
    "#\n",
    "# v1: 20190329, trained on len(replay_memory) = 294912\n",
    "#aero_cnn.save(\"Aero_CNN_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create the moves dictionary\n",
    "#\n",
    "moves = {}\n",
    "\n",
    "for i in range(1, 143):\n",
    "    old_row, old_column, old_direction = process_move_142(i)\n",
    "    \n",
    "    start_row = old_row - 1\n",
    "    start_col = old_column - 1\n",
    "    \n",
    "    if (old_direction == \"down\"):\n",
    "        end_row = start_row + 1\n",
    "        end_col = start_col\n",
    "    elif (old_direction == \"up\"):\n",
    "        end_row = start_row - 1\n",
    "        end_col = start_col\n",
    "    elif (old_direction == \"right\"):\n",
    "        end_row = start_row\n",
    "        end_col = start_col + 1\n",
    "    else:\n",
    "        end_row = start_row\n",
    "        end_col = start_col - 1\n",
    "        \n",
    "    moves[i] = ((start_row, start_col), (end_row, end_col))\n",
    "    \n",
    "print(moves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
