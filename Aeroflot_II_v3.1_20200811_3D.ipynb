{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use bonus plates (length of 4)\n",
    "## Important notes:\n",
    "### - new color model: number of channels = 4, one channel for each color  \n",
    "### - plate value encoded with a number: 0.1, 0.4, 1.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "#import qgrid\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "#from keras.models import Model, load_model, Sequential\n",
    "#from keras.optimizers import Adam\n",
    "#from keras.callbacks import TensorBoard\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "LEARNING_RATE = 0.005\n",
    "UPDATE_TARGET_NET = 1000\n",
    "\n",
    "# Definitions\n",
    "GAMES_TO_PLAY = 120001\n",
    "REPLAY_MEMORY_SIZE = 131072\n",
    "DYNAMIC_LEARNING_EPOCHS = 5\n",
    "MINIBATCH_SIZE = 64\n",
    "NUMBER_OF_MOVES_IN_GAME = 50\n",
    "GAMMA = 0.99\n",
    "ACTIONS_DIMENSION = 142\n",
    "\n",
    "# Variables\n",
    "MAXIMUM_SCORE = 0\n",
    "TOTAL_SCORE_500 = 0.0\n",
    "AVG_SCORE_HIST = []\n",
    "TOTAL_SUCCESSFUL_MOVES_500 = 0.0\n",
    "AVG_SUCC_MOVES_HIST = []\n",
    "CNN_MOVE_PROB = 0.1\n",
    "CNN_MOVES_COUNT = 0\n",
    "CNN_SUCCESSFUL_PREDICTION = 0\n",
    "\n",
    "# Initialize replay_memory\n",
    "replay_memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Definitions\n",
    "#\n",
    "# Order of layers: Red, Green, Blue, Purple\n",
    "#\n",
    "REGULAR_PLATE = 0.1\n",
    "BONUS_PLATE = 0.4\n",
    "\n",
    "COLORS = { 0: \"red\", 1: \"lightgreen\", 2: \"cyan\", 3: \"purple\"}\n",
    "\n",
    "moves = {1: ((0, 0), (1, 0)), 2: ((0, 1), (1, 1)), 3: ((0, 2), (1, 2)), 4: ((0, 3), (1, 3)), 5: ((0, 4), (1, 4)), \n",
    "         6: ((0, 5), (1, 5)), 7: ((1, 0), (2, 0)), 8: ((1, 0), (0, 0)), 9: ((1, 1), (2, 1)), 10: ((1, 1), (0, 1)), \n",
    "         11: ((1, 2), (2, 2)), 12: ((1, 2), (0, 2)), 13: ((1, 3), (2, 3)), 14: ((1, 3), (0, 3)), 15: ((1, 4), (2, 4)), \n",
    "         16: ((1, 4), (0, 4)), 17: ((1, 5), (2, 5)), 18: ((1, 5), (0, 5)), 19: ((2, 0), (3, 0)), 20: ((2, 0), (1, 0)), \n",
    "         21: ((2, 1), (3, 1)), 22: ((2, 1), (1, 1)), 23: ((2, 2), (3, 2)), 24: ((2, 2), (1, 2)), 25: ((2, 3), (3, 3)), \n",
    "         26: ((2, 3), (1, 3)), 27: ((2, 4), (3, 4)), 28: ((2, 4), (1, 4)), 29: ((2, 5), (3, 5)), 30: ((2, 5), (1, 5)), \n",
    "         31: ((3, 0), (4, 0)), 32: ((3, 0), (2, 0)), 33: ((3, 1), (4, 1)), 34: ((3, 1), (2, 1)), 35: ((3, 2), (4, 2)), \n",
    "         36: ((3, 2), (2, 2)), 37: ((3, 3), (4, 3)), 38: ((3, 3), (2, 3)), 39: ((3, 4), (4, 4)), 40: ((3, 4), (2, 4)), \n",
    "         41: ((3, 5), (4, 5)), 42: ((3, 5), (2, 5)), 43: ((4, 0), (5, 0)), 44: ((4, 0), (3, 0)), 45: ((4, 1), (5, 1)), \n",
    "         46: ((4, 1), (3, 1)), 47: ((4, 2), (5, 2)), 48: ((4, 2), (3, 2)), 49: ((4, 3), (5, 3)), 50: ((4, 3), (3, 3)), \n",
    "         51: ((4, 4), (5, 4)), 52: ((4, 4), (3, 4)), 53: ((4, 5), (5, 5)), 54: ((4, 5), (3, 5)), 55: ((5, 0), (6, 0)), \n",
    "         56: ((5, 0), (4, 0)), 57: ((5, 1), (6, 1)), 58: ((5, 1), (4, 1)), 59: ((5, 2), (6, 2)), 60: ((5, 2), (4, 2)), \n",
    "         61: ((5, 3), (6, 3)), 62: ((5, 3), (4, 3)), 63: ((5, 4), (6, 4)), 64: ((5, 4), (4, 4)), 65: ((5, 5), (6, 5)), \n",
    "         66: ((5, 5), (4, 5)), 67: ((6, 0), (5, 0)), 68: ((6, 1), (5, 1)), 69: ((6, 2), (5, 2)), 70: ((6, 3), (5, 3)), \n",
    "         71: ((6, 4), (5, 4)), 72: ((6, 5), (5, 5)), 73: ((0, 0), (0, 1)), 74: ((1, 0), (1, 1)), 75: ((2, 0), (2, 1)), \n",
    "         76: ((3, 0), (3, 1)), 77: ((4, 0), (4, 1)), 78: ((5, 0), (5, 1)), 79: ((6, 0), (6, 1)), 80: ((0, 1), (0, 0)), \n",
    "         81: ((0, 1), (0, 2)), 82: ((1, 1), (1, 0)), 83: ((1, 1), (1, 2)), 84: ((2, 1), (2, 0)), 85: ((2, 1), (2, 2)), \n",
    "         86: ((3, 1), (3, 0)), 87: ((3, 1), (3, 2)), 88: ((4, 1), (4, 0)), 89: ((4, 1), (4, 2)), 90: ((5, 1), (5, 0)), \n",
    "         91: ((5, 1), (5, 2)), 92: ((6, 1), (6, 0)), 93: ((6, 1), (6, 2)), 94: ((0, 2), (0, 1)), 95: ((0, 2), (0, 3)), \n",
    "         96: ((1, 2), (1, 1)), 97: ((1, 2), (1, 3)), 98: ((2, 2), (2, 1)), 99: ((2, 2), (2, 3)), 100: ((3, 2), (3, 1)), \n",
    "         101: ((3, 2), (3, 3)), 102: ((4, 2), (4, 1)), 103: ((4, 2), (4, 3)), 104: ((5, 2), (5, 1)), 105: ((5, 2), (5, 3)), \n",
    "         106: ((6, 2), (6, 1)), 107: ((6, 2), (6, 3)), 108: ((0, 3), (0, 2)), 109: ((0, 3), (0, 4)), 110: ((1, 3), (1, 2)), \n",
    "         111: ((1, 3), (1, 4)), 112: ((2, 3), (2, 2)), 113: ((2, 3), (2, 4)), 114: ((3, 3), (3, 2)), 115: ((3, 3), (3, 4)), \n",
    "         116: ((4, 3), (4, 2)), 117: ((4, 3), (4, 4)), 118: ((5, 3), (5, 2)), 119: ((5, 3), (5, 4)), 120: ((6, 3), (6, 2)), \n",
    "         121: ((6, 3), (6, 4)), 122: ((0, 4), (0, 3)), 123: ((0, 4), (0, 5)), 124: ((1, 4), (1, 3)), 125: ((1, 4), (1, 5)), \n",
    "         126: ((2, 4), (2, 3)), 127: ((2, 4), (2, 5)), 128: ((3, 4), (3, 3)), 129: ((3, 4), (3, 5)), 130: ((4, 4), (4, 3)), \n",
    "         131: ((4, 4), (4, 5)), 132: ((5, 4), (5, 3)), 133: ((5, 4), (5, 5)), 134: ((6, 4), (6, 3)), 135: ((6, 4), (6, 5)), \n",
    "         136: ((0, 5), (0, 4)), 137: ((1, 5), (1, 4)), 138: ((2, 5), (2, 4)), 139: ((3, 5), (3, 4)), 140: ((4, 5), (4, 4)), \n",
    "         141: ((5, 5), (5, 4)), 142: ((6, 5), (6, 4))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_fits_3D(field, i, j, depth):\n",
    "    \"\"\"\n",
    "    Checks if two items to the left or two colors to the bottom or two colors to the right are NOT of the same color as the new item.\n",
    "    \n",
    "    Input:\n",
    "    - field: battfield, numpy array (7, 6, 4)\n",
    "    - i, j, depth: position on the new item, int, within field.shape\n",
    "    Output:\n",
    "    - boolean: True, if the new item is ok\n",
    "    \"\"\"\n",
    "    # Check two colors to the left\n",
    "    if (j > 1):\n",
    "        if (field[i, j - 2, depth] > 0) and (field[i, j - 1, depth] > 0):\n",
    "            return False\n",
    "        \n",
    "    # Check two colors to the right\n",
    "    if (j < 4):\n",
    "        if (field[i, j + 2, depth] > 0) and (field[i, j + 1, depth] > 0):\n",
    "            return False\n",
    "    \n",
    "    # Check two colors to the bottom\n",
    "    if (i < 5):\n",
    "        if (field[i + 2, j, depth] > 0) and (field[i + 1, j, depth] > 0):\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_field_3D(field):\n",
    "    \"\"\"\n",
    "    Initialization of the battle field.\n",
    "    Move from bottom left corner and add new elements.\n",
    "    \n",
    "    Input: \n",
    "    - field: numpy array of zeros, shape = (7, 6, 4)\n",
    "    Output:\n",
    "    - field: numpy array of floats, shape = (7, 6, 4)\n",
    "    \"\"\"\n",
    "    rd.seed()\n",
    "    \n",
    "    for i in reversed(range(field.shape[0])):\n",
    "        for j in range(field.shape[1]):      \n",
    "            new_color = rd.randrange(4)\n",
    "            \n",
    "            while not color_fits_3D(field, i, j, new_color):\n",
    "                new_color = rd.randrange(4)\n",
    "                \n",
    "            field[i, j, new_color] = REGULAR_PLATE\n",
    "    \n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_field_3D(field):\n",
    "    \"\"\"\n",
    "    Visualizes the battle field in colored circles\n",
    "    Handles bonus plates\n",
    "    \n",
    "    Input:\n",
    "    - field: numpy array of floats, (7, 6, 4)\n",
    "    Output:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5, 7))\n",
    "\n",
    "    ax.set_xlim((0, 10))\n",
    "    ax.set_ylim((0, 13))\n",
    "\n",
    "    circles = []\n",
    "\n",
    "    for ii in range(7):\n",
    "        for jj in range(6):\n",
    "            clr = COLORS[field[ii, jj, :].argmax()]\n",
    "\n",
    "            #if (field[ii, jj] // 1 == 1.0):\n",
    "            #    circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=4, radius=0.4, color=clr) )\n",
    "            #else:\n",
    "            #    circles.append( mpatches.Circle((jj + 1, 7 - ii), radius=0.4, color=clr) )\n",
    "             \n",
    "            #\n",
    "            # DEBUG\n",
    "            #\n",
    "            #if (field[ii, jj].sum() == 0.1):\n",
    "            #    circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=3, radius=0.2, color=\"black\") )\n",
    "            #elif (field[ii, jj] // 1 == 1.0):\n",
    "            #    circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=4, radius=0.4, color=clr) )\n",
    "            #else:\n",
    "            #    circles.append( mpatches.Circle((jj + 1, 7 - ii), radius=0.4, color=clr) )\n",
    "            \n",
    "            if (field[ii, jj].sum() == 0.1):\n",
    "                # Regular plate\n",
    "                circles.append( mpatches.Circle((jj + 1, 7 - ii), radius=0.4, color=clr) )\n",
    "            elif (field[ii, jj].sum() == 0.4):\n",
    "                # Bonus plate of 4\n",
    "                circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=4, radius=0.4, color=clr) )\n",
    "            else:\n",
    "                # Premium plate of 5\n",
    "                circles.append( mpatches.RegularPolygon((jj + 1, 7 - ii), numVertices=3, radius=0.2, color=\"black\") )\n",
    "\n",
    "    for circ in circles:\n",
    "        ax.add_artist(circ)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move_v2_3D(field, move, moves):\n",
    "    \"\"\"\n",
    "    Physically moves plates according to the move description\n",
    "    \n",
    "    Input:\n",
    "    - field: numpy array of floats, (7, 6, 4)\n",
    "    - move: particular move to make, 1<=move<=142\n",
    "    - moves: dictionary of all possible moves defined above\n",
    "    Output:\n",
    "    - new_field: updated field with two swapped plates\n",
    "    - plate_start: coordinates of the plate that started the move, tuple (row, column)\n",
    "    - plate_end: cooredinates of the plate that ended the move, tuple (row, column)\n",
    "    \"\"\"\n",
    "    (start_row, start_col), (end_row, end_col) = moves[move]\n",
    "\n",
    "    # Swap two plates and create new (modified) field\n",
    "    new_field = field.copy()\n",
    "    temp_color = field[end_row, end_col, :].copy()\n",
    "    new_field[end_row, end_col, :] = field[start_row, start_col, :]\n",
    "    new_field[start_row, start_col, :] = temp_color\n",
    "        \n",
    "    return new_field, (start_row, start_col), (end_row, end_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_field_3D(field):\n",
    "    \"\"\"\n",
    "    Fills the field after burning the sets\n",
    "    Moves the plates downward, filling the upper row so that it doesn't have \"easy\" sets of three\n",
    "    Starts from the left lower corner, in order to reuse color_fits_3D()\n",
    "    \n",
    "    Input:\n",
    "    - field: numpy array of floats, (7, 6, 4)\n",
    "    Output:\n",
    "    - updated field: numpy array of floats, (7, 6, 4)\n",
    "    \"\"\"  \n",
    "    for ii in reversed(range(field.shape[0])):\n",
    "        for jj in range(field.shape[1]):\n",
    "            while (field[ii, jj, :].sum() == 0.):\n",
    "                # Put downward by one\n",
    "                # Not needed if we are in the uppermost row\n",
    "                if (ii != 0):\n",
    "                    for iii in reversed(range(ii)):\n",
    "                        field[iii + 1, jj, :] = field[iii, jj, :].copy()\n",
    "                    \n",
    "                    field[0, jj, :] = 0.\n",
    "\n",
    "                # Fill the top\n",
    "                new_color = rd.randrange(4)\n",
    "\n",
    "                while not color_fits_3D(field, 0, jj, new_color):\n",
    "                    new_color = rd.randrange(4)\n",
    "\n",
    "                field[0, jj, new_color] = REGULAR_PLATE \n",
    "                \n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets_3D(field):\n",
    "    \"\"\"\n",
    "    Finds all sets and all bonus plates included into those sets\n",
    "    \n",
    "    Input:\n",
    "    - field: numpy array of floats, (7, 6, 4)\n",
    "    Output:\n",
    "    - list of sets coordinates: list of tuples (row_start, column_start, set_length, direction, color), counting from top left corner\n",
    "      Direction is either 0 (horizontal) or 1 (vertical)\n",
    "    - list of bonus plates included into sets: list of tuples (row, column, type). \n",
    "      Type is either 4 or 5 (reserved for future)\n",
    "    \"\"\"\n",
    "    output_bonus_plates = []\n",
    "    output_sets = []\n",
    "\n",
    "    # Find all 3+ sets in horizontal row\n",
    "    for ii in range(field.shape[0]):\n",
    "        temp_bonus_plates = []\n",
    "        jj = 0\n",
    "        len = 1\n",
    "        while (jj < field.shape[1]):\n",
    "            if (jj > 0):\n",
    "                if (((field[ii, jj, :] > 0) == (field[ii, jj - 1, :] > 0)).all()):\n",
    "                    len = len + 1\n",
    "                else:\n",
    "                    if (len >= 3):\n",
    "                        # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "                        output_bonus_plates = output_bonus_plates + temp_bonus_plates\n",
    "                        \n",
    "                        # Add to permanent list of sets\n",
    "                        output_sets.append((ii, jj - len, len, 0, field[ii, jj - 1, :].argmax()))\n",
    "                        \n",
    "                    temp_bonus_plates = []\n",
    "                    len = 1\n",
    "            \n",
    "            if (field[ii, jj, :].sum() > 0.1):\n",
    "                # Add to temp list of bonus plates\n",
    "                temp_bonus_plates.append((ii, jj, 4))\n",
    "            \n",
    "            jj = jj + 1\n",
    "            \n",
    "        if (len >= 3):\n",
    "            # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "            output_bonus_plates = output_bonus_plates + temp_bonus_plates\n",
    "\n",
    "            # Add to permanent list of sets\n",
    "            output_sets.append((ii, jj - len, len, 0, field[ii, jj - 1, :].argmax()))\n",
    "\n",
    "    # Find all 3+ sets in vertical columns\n",
    "    for jj in range(field.shape[1]):\n",
    "        temp_bonus_plates = []\n",
    "        ii = 0\n",
    "        len = 1\n",
    "        while (ii < field.shape[0]):\n",
    "            if (ii > 0):\n",
    "                if (((field[ii, jj, :] > 0) == (field[ii - 1, jj, :] > 0)).all()):\n",
    "                    len = len + 1\n",
    "                else:\n",
    "                    if (len >= 3):\n",
    "                        # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "                        output_bonus_plates = output_bonus_plates + temp_bonus_plates\n",
    "                        \n",
    "                        # Add to permanent list of sets\n",
    "                        output_sets.append((ii - len, jj, len, 1, field[ii - 1, jj, :].argmax()))\n",
    "                        \n",
    "                    temp_bonus_plates = []\n",
    "                    len = 1\n",
    "            \n",
    "            if (field[ii, jj, :].sum() > 0.1):\n",
    "                # Add to temp list of bonus plates\n",
    "                temp_bonus_plates.append((ii, jj, 4))\n",
    "            \n",
    "            ii = ii + 1\n",
    "            \n",
    "        if (len >= 3):\n",
    "            # Add temp list of bonus plates to the permanent list of bonus plates\n",
    "            output_bonus_plates = output_bonus_plates + temp_bonus_plates\n",
    "\n",
    "            # Add to permanent list of sets\n",
    "            output_sets.append((ii - len, jj, len, 1, field[ii - 1, jj, :].argmax()))\n",
    "            \n",
    "    return output_sets, output_bonus_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_in_set_3D(plate, row, col, length, direction):\n",
    "    \"\"\"\n",
    "    Checks whether plate is in the set given by row, col, length, direction\n",
    "    \n",
    "    Input:\n",
    "    - plate: plate location, tuple (row, column)\n",
    "    - row: row where the set starts\n",
    "    - col: column where the set starts\n",
    "    - length: the set's length\n",
    "    - direction: the set's direction\n",
    "    Output:\n",
    "    - True if the plate is within the set, False otherwise\n",
    "    \"\"\"\n",
    "    if (direction == 0):\n",
    "        # Horizontal set\n",
    "        if ((plate[0] != row) or (plate[1] < col) or (plate[1] > (col + length - 1))):\n",
    "            return False\n",
    "    else:\n",
    "        # Vertucal set\n",
    "        if ((plate[1] != col) or (plate[0] < row) or (plate[0] > (row + length - 1))):\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_v2_3D(field, plate_from, plate_to):\n",
    "    \"\"\"\n",
    "    Calculates the score in the field. \n",
    "    Replaces all sets with zeros.\n",
    "    Handles bonus plates: replaces required rows with zeros (Type 4)\n",
    "    Puts bonus plates, should any set be of the length of 4\n",
    "    \n",
    "    Input:\n",
    "    - field: numpy array of floats, (7, 6, 4)\n",
    "    - plate_from: coordinates of the plate where the move starts, tuple (row, column)\n",
    "    - plate_to: coordinates of the plate where the move ends, tuple (row, column)\n",
    "    Output:\n",
    "    - score: int, 0+\n",
    "    - field: modified field, (7, 6, 4)\n",
    "    \"\"\"\n",
    "    # Get all sets with possible bonus plates\n",
    "    sets, bonus_plates = get_sets_3D(field)\n",
    "\n",
    "    # Set all requires plates to zero\n",
    "    #\n",
    "    # First handle sets\n",
    "    for st in sets:\n",
    "        row = st[0]\n",
    "        col = st[1]\n",
    "        lng = st[2]\n",
    "        drc = st[3]\n",
    "\n",
    "        if (drc == 0):\n",
    "            field[row, col:(col + lng), :] = 0.\n",
    "        else:\n",
    "            field[row:(row + lng), col, :] = 0.\n",
    "    #       \n",
    "    # Then handle bonus plates/rows\n",
    "    for pl in bonus_plates:\n",
    "        row = pl[0]\n",
    "        col = pl[1]\n",
    "        typ = pl[2]\n",
    "\n",
    "        if (typ == 4):\n",
    "            field[row, :, :] = 0.\n",
    "\n",
    "    # Calculate score\n",
    "    score = (field.sum(axis=2) == 0.).sum()\n",
    "\n",
    "    # Put new bonus plates. Specially care for the move coordinates\n",
    "    for st in sets:\n",
    "        row = st[0]\n",
    "        col = st[1]\n",
    "        lng = st[2]\n",
    "        drc = st[3]\n",
    "        clr = st[4]\n",
    "\n",
    "        if (lng >= 4):\n",
    "            if (plate_in_set_3D(plate_from, row, col, lng, drc)):\n",
    "                # Move start plate in set. Put new bonus plate according to the move coordinates\n",
    "                field[plate_from[0], plate_from[1], clr] = BONUS_PLATE\n",
    "                \n",
    "                #\n",
    "                # DEBUG\n",
    "                #\n",
    "                #print(\"DEBUG: set of 4+ was made!\")\n",
    "                \n",
    "            elif (plate_in_set_3D(plate_to, row, col, lng, drc)):\n",
    "                # Move end plate in set. Put new bonus plate according to the move coordinates\n",
    "                field[plate_to[0], plate_to[1], clr] = BONUS_PLATE\n",
    "                \n",
    "                #\n",
    "                # DEBUG\n",
    "                #\n",
    "                #print(\"DEBUG: set of 4+ was made!\")\n",
    "                \n",
    "            else:\n",
    "                # Just put the new bonus plate at the very right/bottom of the set\n",
    "                # This CANNOT happen during the manual move!\n",
    "                # It CAN ONLY HAPPEN when the field is randomly filled with new plates\n",
    "                if (drc == 0):\n",
    "                    field[row, col + lng - 1, clr] = BONUS_PLATE\n",
    "                else:\n",
    "                    field[row + lng - 1, col, clr] = BONUS_PLATE\n",
    "\n",
    "    return score, field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Memory Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Replay memory buffer\n",
    "#\n",
    "class ExperienceBuffer():\n",
    "    '''\n",
    "    Experience Replay Buffer\n",
    "    Inspired by Andrea Lonza\n",
    "    '''\n",
    "\n",
    "    def __init__(self, buffer_size, gamma):\n",
    "        # Constants\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Main Replay Memory buffer parts\n",
    "        self.states_before = deque(maxlen=buffer_size)\n",
    "        self.actions = deque(maxlen=buffer_size)\n",
    "        self.total_rewards = deque(maxlen=buffer_size)\n",
    "        self.states_after = deque(maxlen=buffer_size)\n",
    "        self.last_moves = deque(maxlen=buffer_size)\n",
    "   \n",
    "    \n",
    "    def add(self, state_before, action, reward, state_after, last_move):\n",
    "        # Add certain items to corresponding buffers\n",
    "        self.states_before.append(state_before)\n",
    "        self.actions.append(action)\n",
    "        self.total_rewards.append(reward)\n",
    "        self.states_after.append(state_after)\n",
    "        self.last_moves.append(last_move)\n",
    "    \n",
    "    \n",
    "    def sample_minibatch(self, minibatch_size):\n",
    "        '''\n",
    "        Sample a minibatch of size batch_size\n",
    "        Note1: always add the most recent completed move\n",
    "        '''\n",
    "        indices = rd.sample(range(len(self.states_before) - 1), minibatch_size - 1)\n",
    "        # Add the most recent completed move index\n",
    "        indices.append(len(self.states_before) - 1)\n",
    "        \n",
    "        minibatch_states_before = np.array([self.states_before[i] for i in indices]) \n",
    "        minibatch_actions = np.array([self.actions[i] for i in indices]) \n",
    "        minibatch_total_rewards = np.array([self.total_rewards[i] for i in indices]) \n",
    "        minibatch_states_after = np.array([self.states_after[i] for i in indices])  \n",
    "        minibatch_last_moves = np.array([self.last_moves[i] for i in indices])   \n",
    "        \n",
    "        return minibatch_states_before, minibatch_actions, minibatch_total_rewards, minibatch_states_after, minibatch_last_moves\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return length of the current replay memory buffer\n",
    "        Relevant for the first *minibatch_size* moves.\n",
    "        '''\n",
    "        return len(self.states_before)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Nework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_memory = ExperienceBuffer(REPLAY_MEMORY_SIZE, GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Online CNN and Target CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online CNN\n",
    "Online_CNN = tf.keras.models.Sequential()\n",
    "Online_CNN.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides = (1, 1), padding='same', activation=tf.keras.activations.relu, data_format = 'channels_last', input_shape=(7, 6, 4)))\n",
    "Online_CNN.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides = (1, 1), padding='same', activation=tf.keras.activations.relu))    \n",
    "Online_CNN.add(tf.keras.layers.Flatten())                      \n",
    "Online_CNN.add(tf.keras.layers.Dense(ACTIONS_DIMENSION, activation=tf.keras.activations.relu, kernel_initializer='RandomNormal'))\n",
    "\n",
    "# Target CNN\n",
    "Target_CNN = tf.keras.models.Sequential()\n",
    "Target_CNN.add(tf.keras.layers.Conv2D(64, kernel_size=3, strides = (1, 1), padding='same', activation=tf.keras.activations.relu, data_format = 'channels_last', input_shape=(7, 6, 4)))\n",
    "Target_CNN.add(tf.keras.layers.Conv2D(128, kernel_size=3, strides = (1, 1), padding='same', activation=tf.keras.activations.relu))    \n",
    "Target_CNN.add(tf.keras.layers.Flatten())                      \n",
    "Target_CNN.add(tf.keras.layers.Dense(ACTIONS_DIMENSION, activation=tf.keras.activations.relu, kernel_initializer='RandomNormal'))\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "# Set weights equal\n",
    "Target_CNN.set_weights(Online_CNN.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of moves made to follow the target CNN update strategy\n",
    "total_moves = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "New maximum: 51, after 0 games.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "New maximum: 58, after 2 games.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "New maximum: 82, after 3 games.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "New maximum: 95, after 6 games.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5562\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5564\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5565\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5566\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "                                                      \n",
    "for game in range(GAMES_TO_PLAY):\n",
    "    # Start one game\n",
    "    game_score = 0\n",
    "    successful_moves = 0\n",
    "\n",
    "    # Initialize the game field\n",
    "    field = np.zeros((7, 6, 4))\n",
    "    field = initialize_field_3D(field)\n",
    "\n",
    "    for m in range(NUMBER_OF_MOVES_IN_GAME):\n",
    "        # Total score of one move\n",
    "        reward = 0\n",
    "\n",
    "        # Whether CNN made the move\n",
    "        cnn_made_move_flag = False\n",
    "        \n",
    "        # If replay_memory has less than 64 moves, then make a random move\n",
    "        if ((len(replay_memory) < MINIBATCH_SIZE) or (rd.random() > CNN_MOVE_PROB)):\n",
    "            move = rd.randint(1, ACTIONS_DIMENSION)\n",
    "        else:\n",
    "            # CNN selects a move\n",
    "            cnn_made_move_flag = True\n",
    "            X_data = np.expand_dims(np.copy(field), axis=0)\n",
    "            move = Target_CNN.predict(X_data).argmax() + 1\n",
    "\n",
    "        # Make the move\n",
    "        new_field, plate_a, plate_b = make_move_v2_3D(field.copy(), move, moves)\n",
    "\n",
    "        # Calculate the score and update the field\n",
    "        score, new_field = calculate_score_v2_3D(new_field, plate_a, plate_b)\n",
    "        \n",
    "        # If the move is successful, then update the field and check if we have new sets        \n",
    "        successful_move_flag = False\n",
    "\n",
    "        # While we have new sets (thus the score is greater than 0), process them, calculate score and move plates\n",
    "        while (score > 0.):\n",
    "            if (not successful_move_flag):\n",
    "                successful_moves = successful_moves + 1\n",
    "                successful_move_flag = True\n",
    "\n",
    "            # Add new points to the total score of the move\n",
    "            reward = reward + score\n",
    "\n",
    "            # Move plates downward, fill the upper row so, that it doesn't have \"easy\" sets of three\n",
    "            # Start from the left lower corner (in order to reuse color_fits())\n",
    "            new_field = fill_field_3D(new_field)\n",
    "\n",
    "            # Calculate score and check whether we have new sets\n",
    "            score, new_field = calculate_score_v2_3D(new_field, (-1, -1), (-1, -1))\n",
    "\n",
    "        # Increase the score of the whole game\n",
    "        game_score = game_score + reward\n",
    "        \n",
    "        # Update CNN move statistics\n",
    "        if (cnn_made_move_flag):\n",
    "            if (successful_move_flag):\n",
    "                CNN_SUCCESSFUL_PREDICTION = CNN_SUCCESSFUL_PREDICTION + 1\n",
    "                \n",
    "            CNN_MOVES_COUNT = CNN_MOVES_COUNT + 1\n",
    "            \n",
    "        # Check whether it's the last move of the current game\n",
    "        last_move = m == NUMBER_OF_MOVES_IN_GAME - 1\n",
    "        \n",
    "        # Add new move to the replay memory\n",
    "        replay_memory.add(field, move, reward, new_field, last_move)\n",
    "        \n",
    "        #\n",
    "        # Train CNN based on the score\n",
    "        #\n",
    "        if (len(replay_memory) >= MINIBATCH_SIZE):\n",
    "            # Select random MINIBATCH_SIZE moves from replay memory buffer\n",
    "            samples = replay_memory.sample_minibatch(MINIBATCH_SIZE)\n",
    "\n",
    "            # Prepare some things for training\n",
    "            s_before = samples[0]\n",
    "            actions = samples[1]\n",
    "            rewards = samples[2]\n",
    "            s_after = samples[3] \n",
    "            dones = samples[4]\n",
    "            \n",
    "            # Update online CNN weights: training step\n",
    "            for _ in range(DYNAMIC_LEARNING_EPOCHS):\n",
    "                rewards_next = np.max(Target_CNN(s_after), axis=1)\n",
    "                actual_values = np.where(dones, rewards, rewards + GAMMA*rewards_next)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    prediction = Online_CNN(s_before)\n",
    "\n",
    "                    selected_action_values = tf.math.reduce_sum(prediction*tf.one_hot(actions, ACTIONS_DIMENSION), axis=1)  \n",
    "\n",
    "                    loss = tf.math.reduce_mean(tf.square(actual_values - selected_action_values))\n",
    "\n",
    "                gradients = tape.gradient(loss, Online_CNN.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(gradients, Online_CNN.trainable_weights))\n",
    "\n",
    "        # If move is successful, update the play field\n",
    "        if (successful_move_flag):\n",
    "            field = np.copy(new_field)\n",
    "            \n",
    "        # After each 1000 moves update target CNN\n",
    "        if (total_moves % UPDATE_TARGET_NET == 0):\n",
    "            Target_CNN.set_weights(Online_CNN.get_weights())\n",
    "            \n",
    "        total_moves = total_moves + 1\n",
    "\n",
    "    #\n",
    "    # Calculate and display overall stats\n",
    "    #\n",
    "    # Check whether we have new maximum score\n",
    "    if (game_score > MAXIMUM_SCORE):\n",
    "        print(f\"New maximum: {game_score}, after {game} games.\")\n",
    "        MAXIMUM_SCORE = game_score\n",
    "        \n",
    "    # After each 500 games output average game score, average number of successful moves per game\n",
    "    TOTAL_SCORE_500 = TOTAL_SCORE_500 + game_score\n",
    "    TOTAL_SUCCESSFUL_MOVES_500 = TOTAL_SUCCESSFUL_MOVES_500 + successful_moves\n",
    "    \n",
    "    if ((game % 500 == 0) and (game > 0)):\n",
    "        avg_score = TOTAL_SCORE_500 / 500\n",
    "        TOTAL_SCORE_500 = 0.0\n",
    "        \n",
    "        avg_succ_moves = TOTAL_SUCCESSFUL_MOVES_500 / 500\n",
    "        AVG_SUCC_MOVES_HIST.append(avg_succ_moves)\n",
    "        TOTAL_SUCCESSFUL_MOVES_500 = 0.0\n",
    "\n",
    "        print(f\"Games: {game}, last 100 games avg score: {avg_score}, avg of successful moves: {avg_succ_moves}, loss {loss}\")        \n",
    "        print(f\"CNN made {CNN_MOVES_COUNT} moves. Successful were {CNN_SUCCESSFUL_PREDICTION}\")\n",
    "        \n",
    "        if (CNN_SUCCESSFUL_PREDICTION / CNN_MOVES_COUNT >= CNN_MOVE_PROB):\n",
    "            CNN_MOVE_PROB = CNN_MOVE_PROB + 0.1\n",
    "            \n",
    "        CNN_MOVES_COUNT = 0\n",
    "        CNN_SUCCESSFUL_PREDICTION = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    }
   ],
   "source": [
    "# tensorboard --logdir=./logs --bind_all &\n",
    "\n",
    "print(MAXIMUM_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#field = np.zeros((7, 6))\n",
    "\n",
    "df = pd.DataFrame(updated_field)\n",
    "qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updated_df = qgrid_widget.get_changed_df()\n",
    "updated_field = updated_df.values\n",
    "visualize_field(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sets(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, new_field = calculate_score_v2(updated_field, (6, 3), (5, 3))\n",
    "print(score)\n",
    "visualize_field(updated_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_field_2 = fill_field(updated_field, colors)\n",
    "#visualize_field(updated_field_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the CNN has been trained.\n",
    "### Start the long reinforcement-learning cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "successful_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_field = make_move(field, move)\n",
    "print(new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_field = calculate_score(new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_field = np.multiply(new_field, 1.0 - temp_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_field(new_field, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save model\n",
    "#\n",
    "# v1: 20190329, trained on len(replay_memory) = 294912\n",
    "#aero_cnn.save(\"Aero_CNN_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create the moves dictionary\n",
    "#\n",
    "moves = {}\n",
    "\n",
    "for i in range(1, 143):\n",
    "    old_row, old_column, old_direction = process_move_142(i)\n",
    "    \n",
    "    start_row = old_row - 1\n",
    "    start_col = old_column - 1\n",
    "    \n",
    "    if (old_direction == \"down\"):\n",
    "        end_row = start_row + 1\n",
    "        end_col = start_col\n",
    "    elif (old_direction == \"up\"):\n",
    "        end_row = start_row - 1\n",
    "        end_col = start_col\n",
    "    elif (old_direction == \"right\"):\n",
    "        end_row = start_row\n",
    "        end_col = start_col + 1\n",
    "    else:\n",
    "        end_row = start_row\n",
    "        end_col = start_col - 1\n",
    "        \n",
    "    moves[i] = ((start_row, start_col), (end_row, end_col))\n",
    "    \n",
    "print(moves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
